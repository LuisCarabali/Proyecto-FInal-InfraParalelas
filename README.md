ğŸ§  Proyecto Final - Infraestructuras Paralelas y Distribuidas

**Estudiante:** Luis CarabalÃ­, Victor AcuÃ±a, Nicolas Granada.  
**Universidad del Valle**  
**Curso:** Infraestructura Paralela y Distribuida  
**Tema:** Machine Learning paralelo con Ray, FastAPI, Docker y despliegue en AWS EC2

---

## ğŸ¯ Objetivo

Implementar y comparar una soluciÃ³n de clasificaciÃ³n con Machine Learning ejecutada en forma **secuencial** y **paralela**, desplegando la soluciÃ³n como un microservicio en la nube.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- ğŸ Python 3
- ğŸ¤– scikit-learn
- âš¡ Ray (paralelismo)
- ğŸš€ FastAPI
- ğŸ³ Docker + Docker Compose
- â˜ï¸ AWS EC2
- ğŸ™ GitHub

---

## âš™ï¸ Estructura del proyecto

Proyecto-Final/
â”‚
â”œâ”€â”€ ray_parallel/ # Entrenamiento en paralelo usando Ray
â”‚ â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ sequential/ # Entrenamiento secuencial
â”‚ â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ api_service/ # API con FastAPI para predicciÃ³n
â”‚ â””â”€â”€ main.py
â”‚
â”œâ”€â”€ docker-compose.yml # OrquestaciÃ³n de servicios
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

## ğŸ§ª Instrucciones de uso

### ğŸ§± Requisitos

- Python 3.10 o superior
- Docker y Docker Compose
- Git

### ğŸš€ Entrenamiento local

Secuencial:

```bash
python3 sequential/train_model.py


---

## ğŸ§ª Instrucciones de uso

### ğŸ§± Requisitos

- Python 3.10 o superior
- Docker y Docker Compose
- Git

### ğŸš€ Entrenamiento local

Secuencial:

```bash
python3 sequential/train_model.py

python3 ray_parallel/train_model.py

cd api_service
docker build -t ray-api .
docker run -p 8000:8000 ray-api

Accede en: http://localhost:8000/docs

â˜ï¸ Despliegue en AWS EC2
Subir el proyecto con scp

Instalar dependencias (docker, python3, etc.)

Ejecutar: docker-compose up --build -d

Accede en: http://13.59.51.54:8000/docs

ğŸ“Š Resultados
VersiÃ³n	PrecisiÃ³n	Tiempo aprox
Secuencial	0.9759	~0.4 s
Paralelo	0.9750	~2.4 s

Nota: En instancias t3.micro fue necesario reducir el tamaÃ±o del dataset y ajustar los parÃ¡metros de Ray para evitar errores de memoria.

âœ… Conclusiones
Se implementÃ³ exitosamente el paralelismo con Ray.

Se desplegÃ³ una API funcional en la nube con Docker.

Se evaluÃ³ rendimiento entre ejecuciÃ³n secuencial vs. paralela.

Se usaron herramientas reales de DevOps y ML como en entornos profesionales.
